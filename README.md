# Movies-ETL

A project in performing an ETL ( Extract, Transform, Load ) process to create data pipelines using Python, Pandas and PostgreSQL using very large data files.

## Overview
The purpose of this project was to create an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables that is connected to a database.<br/>
Within the scope of the AmazingPrime Hackathon, this project will create an automated pipeline that takes in new data from Wikipedia, Kaggle metadata and the MovieLens ratings data. It then performs the appropriate transformations and loads the data into an existing PostgreSQL database.<br/>
For this analysis, we used the following breakdown:
  1. write an ETL function to read three data files.
  2. extract and transform the Wikipedia data.
  3. extract and transform the Kaggle and rating data.
  4. load the data to a PostgreSQL Movie Database.


### Resources
  - Data sources : [wikipedia_movies.json](), &nbsp; [movies_metadata.csv]()
  - Softwares : [PostgreSQL](https://www.enterprisedb.com/downloads/postgres-postgresql-downloads),&nbsp; [Python](https://www.python.org/downloads/windows/), &nbsp; [Pandas](https://www.anaconda.com/products/distribution)
